# WikibaseIntegrator


> ðŸ“Œ local wikibaseì— ë°ì´í„° import í…ŒìŠ¤íŠ¸ ê²°ê³¼
> 
> [ì°¸ê³ ìžë£Œ]
> - ê¹ƒí—™: https://github.com/SemanticLab/data-2-wikibase
> - ê°€ì´ë“œ: [https://learningwikibase.com/data-import/](https://learningwikibase.com/data-import/)


# 1.  ê°€ìƒí™˜ê²½ ì„¤ì •

> ðŸ’¡ ê°€ìƒí™˜ê²½ì—ì„œ ì„¤ì¹˜í•´ì•¼ í•˜ëŠ” ì´ìœ .    
> - pywikibotì„ `pip isntall pywikibot` í–ˆì„ ë•ŒëŠ” localì˜ wikibaseì™€ ì—°ê²°í•˜ê¸° ìœ„í•´ì„œ í¬íŠ¸ ë²ˆí˜¸ ë³€ê²½í•˜ëŠ” íŒŒì¼ì„ ìˆ˜ì •í•´ì¤„ ìˆ˜ ì—†ìŒ. 
> - pywikibot ê¹ƒí—™ì„ í´ë¡ í•´ì„œ (íŒŒì¼ì´ë¦„ core) í•˜ìœ„ íŒŒì¼ë“¤ ìˆ˜ì •í•˜ê³ (ì•„ëž˜ ì°¸ê³ ) ê°€ìƒí™˜ê²½ì—ì„œ ë¶ˆëŸ¬ì™€ì„œ ëª¨ë“ˆ ìž„í¬íŠ¸í•´ì„œ í•´ê²°
> - ê¸°ë³¸ ê°€ìƒí™˜ê²½(?) ë§Œë“¤ì–´ì„œ í•´ë„ ë˜ëŠ”ë°, ì—°ê²°ì´ ìž˜ ì•ˆë¼ì„œ ì•„ë‹ˆì½˜ë‹¤ì—ì„œ ê°€ìƒí™˜ê²½ ë§Œë“  ê²ƒ (ë¡œì»¬ python kernel ì—°ê²°ì´ ë­”ê°€ ê¼¬ì¸ë“¯. ê·¸ëƒ¥ ê°€ìƒí™˜ê²½ ë§Œë“¤ì–´ì„œ ì—°ê²° ìž˜ ë˜ë©´ ì•„ë‚˜ì½˜ë‹¤ì—ì„œ ì•ˆë§Œë“¤ì–´ë„ ë¨)


### 1.1. [ì•„ë‚˜ì½˜ë‹¤ ê°€ìƒí™˜ê²½ ì„¤ì •](https://sdc-james.gitbook.io/onebook/2./2.1./2.1.1./2-conda-virtual-environments)

- `conda create -n wikibase python=3.7`
- ê°€ìƒí™˜ê²½ ì‹¤í–‰í•˜ê¸° `conda activate wikibase`
    
    terminalì´ëž‘ jupyter notebook kernelì´ëž‘ ë‘˜ë‹¤ ê°€ìƒí™˜ê²½ìœ¼ë¡œ ì„¤ì •ëëŠ”ì§€ í™•ì¸í•˜ê¸°
    

# 2. github repoë§Œë“¤ì–´ì„œ clone

- cloneí•œ í´ë”ì— ipynb íŒŒì¼ í•˜ë‚˜ ë§Œë“¤ê³  ê°€ìƒí™˜ê²½ kerneldmfh ì ‘ì†í•˜ê¸°

# 3. pywikibot ì„¤ì¹˜í•˜ê¸°

### 3.1. pywikibot git clone

- í•´ë‹¹ ê¹ƒí—™ ê°€ì´ë“œ ì°¸ê³ : â€£
- `git clone https://gerrit.wikimedia.org/r/pywikibot/core.git`

### 3.2. ì¶”ê°€ ì„¤ì¹˜í•˜ê¸°

1. `pip install requests`
2. `pip install -r requirements.txt`
3. cd core ë“¤ì–´ê°€ì„œ `git submodule update --init`  â†’ ì¡°ê¸ˆ ì˜¤ëž˜ê±¸ë¦¼
4. `python pwb.py login -all` 
    
    ì´ê±° í•˜ë©´ `NOTE: [user-config.py](http://user-config.py/) was not found!` ì´ë¼ëŠ” ë§ ë‚˜ì˜¤ë©´ì„œ ìƒˆë¡œ ìƒì„± ì‹œìž‘l
    
    ![Untitled](WikibaseIntegrator%208af300c92536484c923c9ec25e00ff30/Untitled.png)
    
    - family ì„ íƒí•  ë•Œ mediawikië¡œ ì§„í–‰ (wikidataë„ ë˜ê¸´ í•˜ëŠ”ë° ì–¸ì–´ ì„¤ì • ë¶€ë¶„ì´ í™•ì‹¤í•˜ì§€ ì•ŠìŒ)
    - username, bot name, bot password ì¹˜ê³  ë‚˜ì„œ ì•„ëž˜ì™€ ê°™ì€ ì§ˆë¬¸ ë‚˜ì™”ì„ ë•Œ ë‹¤ a(ì „ì²´ ë‹¤ ì„ íƒí•¨) ëˆ„ë¥´ë©´ [user-config.py](http://user-config.py) íŒŒì¼ ìƒì„± ì™„ë£Œë¨
    
    ![Untitled](WikibaseIntegrator%208af300c92536484c923c9ec25e00ff30/Untitled%201.png)
    

### 3.3. core/user-config.py íŒŒì¼ ìˆ˜ì •í•˜ê¸°

- [user-config.py](http://user-config.py) íŒŒì¼ ìž˜ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê¸°
- ì¶”ê°€ìˆ˜ì •í•˜ê¸°
    - `family_files['wikipedia'] = '[http://localhost:4100/](http://localhost:4100/)'` ì¶”ê°€
    - paddword_file ê²½ë¡œ ì§€ì •
    - mylang ì— ë‹¤ë¥¸ ì–¸ì–´ë„ ë„£ì–´ì£¼ê³  ì‹¶ë‹¤ë©´ ë˜‘ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë„£ìœ¼ë©´ ë¨ (ex. `mylnag = 'ko'`)
    
    ![Untitled](WikibaseIntegrator%208af300c92536484c923c9ec25e00ff30/Untitled%202.png)
    

### 3.4. core/user-password.py íŒŒì¼ ìˆ˜ì •í•˜ê¸°

- í˜•ì‹ì´ ì•„ëž˜ì™€ ë‹¤ë¥´ê²Œ ì €ìž¥ë˜ì–´ ìžˆì„ ìˆ˜ ìžˆìŒ. ì•„ëž˜ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ìˆ˜ì •í•˜ê¸°
    
    ![Untitled](WikibaseIntegrator%208af300c92536484c923c9ec25e00ff30/Untitled%203.png)
    

### 3.5. core/pywikibot/config.py íŒŒì¼ ìˆ˜ì •í•˜ê¸°

- user_config_file ë³€ìˆ˜ì— get_user_confifg_file() í•¨ìˆ˜ ì“°ì§€ ë§ê³  ê·¸ëƒ¥ [user-config.py](http://user-config.py) ê²½ë¡œë¡œ ë°”ë¡œ ë„£ì–´ì£¼ê¸°
    
    ![Untitled](WikibaseIntegrator%208af300c92536484c923c9ec25e00ff30/Untitled%204.png)
    

# 4. ipynb: CONNECT

1. coreì˜ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
    
    ```python
    import sys
    sys.path.append('/Users/jeongyunl/Documents/GitHub/wikibaseIntegrator_jyl/core')
    print(sys.path)
    ```
    
2. local wikibase ì—°ê²°í•˜ê¸°
    
    ```python
    from wikibaseintegrator import WikibaseIntegrator
    from wikibaseintegrator.wbi_config import config as wbi_config
    
    wbi_config['MEDIAWIKI_API_URL'] = 'http://localhost:4100/w/api.php'
    wbi_config['SPARQL_ENDPOINT_URL'] = 'http://localhost:8834/proxy/wdqs/bigdata/namespace/wdq/sparql'
    wbi_config['WIKIBASE_URL'] = 'http://wikibase.svc'
    wbi_config['USER_AGENT'] = 'MyWikibaseBot/1.0 (https://www.wikidata.org/wiki/User:JeongYun Lee)'
    ```
    
3. login
    
    ```python
    from wikibaseintegrator import wbi_login
    
    login_instance = wbi_login.Login(user='JeongYun Lee', password='*****, mediawiki_api_url='http://localhost:4100/w/api.php')
    ```
    
4. pywikibot install
    
    ```python
    import pywikibot, json, csv, sys
    from pywikibot import family
    ```
    

# 5. ipynb: ADD PROPERTIES

```python

"""
    Notes:
    We need to remove the built in throttling because we 
    are working on our own localhost running wikibase, we don't
    care if we do a ton of requests, we are likely the only user
"""
# over write it
def wait(self, seconds):
    """Wait for seconds seconds.
    Announce the delay if it exceeds a preset limit.
    """
    pass

pywikibot.throttle.Throttle.wait = wait

if __name__ == "__main__":

    csv_path = '/Users/jeongyunl/Documents/GitHub/wikibaseIntegrator_address_test2/testData/add_properties.csv'
    csv_file = open(csv_path,'r', encoding='utf-8-sig')
    csv_reader = csv.DictReader(csv_file)

	  ### ë¡œê·¸ì¸ ì´ë¯¸ í–ˆìœ¼ë¯€ë¡œ ì•ˆí•´ë„ ë¨
    site = pywikibot.Site('mediawiki:mediawiki')
    #site.login()

    complete_data = []

    for row in csv_reader:
        row = dict(row)
        
        data = {
            'datatype': row['Datatype'],  # mandatory
            'descriptions': {
                'ko': {
                    'language': 'ko',
                    'value': row['Property Description']
                }
            },
            'labels': {
                'ko': {
                    'language': 'ko',
                    'value': row['Property Label']
                }
            }
        }

        params = {
            'action': 'wbeditentity',
            'new': 'property',
            'data': json.dumps(data),
            'summary': 'bot adding in properties',
            'token': site.tokens['csrf']
            # 'token': site.tokens['edit']
        }

        req = site._simple_request(**params)
        results = req.submit()

        row['PID'] = results['entity']['id']

        print(row['PID'], row['Property Label'])
        complete_data.append(row)

    csv_file.close()

    with open(csv_path+'_updated.csv','w') as out:

        fieldnames = list(complete_data[0].keys())
        writer = csv.DictWriter(out, fieldnames=fieldnames)

        writer.writeheader()
        writer.writerows(complete_data)
```

# 6. ipynb: ADD CORE ITEMS

```python
import wikidataintegrator as WI
import requests, csv, sys, re

########## part1 ##########
WI.wdi_core.WDItemEngine.core_props = { 
    'P50': {
        'datatype': 'string',
        'name': 'ì‹ë³„ìž', 
        'domain': ['addresTerms'], # this is a wikidataintergrator thing, to group properties together
        'core_id': True 
    }
}

use_unique_property = 'P50:string'

if __name__ == "__main__":

    csv_path = '/Users/jeongyunl/Documents/Github/wikibaseintegrator_address_test2/testData/add_core_items.csv'
    csv_file = open(csv_path,'r', encoding='utf-8-sig')
    csv_reader = csv.DictReader(csv_file)

    complete_data = []
    errors_data = []

    for row in csv_reader:
        row = dict(row)

        data = []

        # properties stuff     
        for key in row:

            # is it a property field
            if key.find(':') > -1 and key[0] == "P":
                PID, data_type = key.split(':')

                # there are few other data types need to add...
                try:
                    if data_type.lower() == 'string':
                        if row[key] is not None and row[key].strip() != '':
                            statement = WI.wdi_core.WDString(value=row[key], prop_nr=PID)
                            data.append(statement)
                    elif data_type.lower() == 'url':
                        if row[key] is not None and row[key].strip() != '':
                            statement = WI.wdi_core.WDUrl(value=row[key], prop_nr=PID)
                            data.append(statement)
                    elif data_type.lower() == 'wikibase-item':
                        if row[key] is not None and row[key].strip() != '':
                            statement = WI.wdi_core.WDItemID(value=row[key], prop_nr=PID)
                            data.append(statement)

                    
                except Exception as e:
                    print("There was an error with this part1, skipping:")
                    print(row)
                    print(e)
                    errors_data.append(row)
                    data = "error"

        if data == 'error':
            continue

        if use_unique_property in row:
            item_name = row[use_unique_property]
        else:
            item_name = None

########## part2 ##########
        domain = 'addresTerms'

        try:
            wd_item = WI.wdi_core.WDItemEngine(new_item=True, data=data, mediawiki_api_url="http://localhost:4100/w/api.php")

            # set the label and description if exists
            if 'Label' in row:
                if row['Label'] is not None and row['Label'].strip() != '':
                    wd_item.set_label(row['Label'])

            if 'Description' in row:
                if row['Description'] is not None and row['Description'].strip() != '':
                    wd_item.set_description(row['Description'])
       

            # write
            r = wd_item.write(login_instance)
            print("goodbye!")
            
            # QID is returned
            row['QID'] = r

            print(row['QID'], row['Label'])

            
            complete_data.append(row)

        except Exception as e:
            print("There was an error with this part2, skipping:")
            print(row)
            print(e)
            errors_data.append(row)
            data = "error"

    csv_file.close()

    with open(csv_path+'_updated.csv','w') as out:

        fieldnames = list(complete_data[0].keys())
        writer = csv.DictWriter(out, fieldnames=fieldnames)

        writer.writeheader()
        writer.writerows(complete_data)

    if len(errors_data) > 0:
        with open(csv_path+'_errors.csv','w') as out:

            fieldnames = list(errors_data[0].keys())
            writer = csv.DictWriter(out, fieldnames=fieldnames)

            writer.writeheader()
            writer.writerows(errors_data)
```

# 7. ipynb: ADD ITEMS

ADD CORE ITEMSì™€ ì½”ë“œ ë™ì¼í•¨

```python
import wikidataintegrator as WI
import requests, csv, sys, re

########## part1 ##########
WI.wdi_core.WDItemEngine.core_props = { 
    'P50': {
        'datatype': 'string',
        'name': 'ì‹ë³„ìž', 
        'domain': ['addresTerms'], # this is a wikidataintergrator thing, to group properties together
        'core_id': True 
    }
}

use_unique_property = 'P8:string'

if __name__ == "__main__":

    csv_path = '/Users/jeongyunl/Documents/Github/wikibaseintegrator_address_test2/testData/add_core_items.csv'
    csv_file = open(csv_path,'r', encoding='utf-8-sig')
    csv_reader = csv.DictReader(csv_file)

    complete_data = []
    errors_data = []

    for row in csv_reader:
        row = dict(row)

        data = []

        # properties stuff     
        for key in row:

            # is it a property field
            if key.find(':') > -1 and key[0] == "P":
                PID, data_type = key.split(':')

                # there are few other data types need to add...
                try:
                    if data_type.lower() == 'string':
                        if row[key] is not None and row[key].strip() != '':
                            statement = WI.wdi_core.WDString(value=row[key], prop_nr=PID)
                            data.append(statement)
                    elif data_type.lower() == 'url':
                        if row[key] is not None and row[key].strip() != '':
                            statement = WI.wdi_core.WDUrl(value=row[key], prop_nr=PID)
                            data.append(statement)
                    elif data_type.lower() == 'wikibase-item':
                        if row[key] is not None and row[key].strip() != '':
                            statement = WI.wdi_core.WDItemID(value=row[key], prop_nr=PID)
                            data.append(statement)

                    
                except Exception as e:
                    print("There was an error with this part1, skipping:")
                    print(row)
                    print(e)
                    errors_data.append(row)
                    data = "error"

        if data == 'error':
            continue

        if use_unique_property in row:
            item_name = row[use_unique_property]
        else:
            item_name = None

########## part2 ##########
        domain = 'addresTerms'

        try:
            wd_item = WI.wdi_core.WDItemEngine(new_item=True, data=data, mediawiki_api_url="http://localhost:4100/w/api.php")

            # set the label and description if exists
            if 'Label' in row:
                if row['Label'] is not None and row['Label'].strip() != '':
                    wd_item.set_label(row['Label'])

            if 'Description' in row:
                if row['Description'] is not None and row['Description'].strip() != '':
                    wd_item.set_description(row['Description'])
       

            # write
            r = wd_item.write(login_instance)
            print("goodbye!")
            
            # QID is returned
            row['QID'] = r

            print(row['QID'], row['Label'])

            
            complete_data.append(row)

        except Exception as e:
            print("There was an error with this part2, skipping:")
            print(row)
            print(e)
            errors_data.append(row)
            data = "error"

    csv_file.close()

    with open(csv_path+'_updated.csv','w') as out:

        fieldnames = list(complete_data[0].keys())
        writer = csv.DictWriter(out, fieldnames=fieldnames)

        writer.writeheader()
        writer.writerows(complete_data)

    if len(errors_data) > 0:
        with open(csv_path+'_errors.csv','w') as out:

            fieldnames = list(errors_data[0].keys())
            writer = csv.DictWriter(out, fieldnames=fieldnames)

            writer.writeheader()
            writer.writerows(errors_data)
```
